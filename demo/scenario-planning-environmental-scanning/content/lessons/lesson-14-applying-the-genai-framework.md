# Applying the GenAI Framework 

## Introductory Context 

This chapter explores how generative AI can support environmental scanning, trend analysis, scenario planning, stress-testing, and the translation of foresight into operational strategy. Together, these practices form a foresight “engine” for higher education institutions: sensing change, making sense of it, rehearsing multiple futures, and adjusting plans in response.

The AI Capability Framework (2026) offers a values-based way to use these tools without sliding into techno-solutionism. It asks not just *what* we can do with GenAI, but *how* and *why* we integrate it into institutional intelligence. In this exercise, you will apply the six domains to a complete foresight cycle: from real-time environmental scanning through to stress-testing institutional plans and linking scenarios to operational strategy.

You can use this section as a CPD workshop script, a postgraduate learning activity, or a facilitated team exercise. The goal is to build a shared, ethical, and practical approach to AI-augmented foresight that is realistic in busy institutional contexts, but still ambitious enough to change how your organisation thinks about the future.

## Domain 1 – AI Awareness & Orientation

## Seeing the Foresight System Clearly

### **Scenario** 

A small strategy unit has set up an AI-assisted environmental scanning workflow: n8n automations collect policy updates, sector news, and research funding announcements. A ChatGPT-style assistant produces weekly “foresight briefs” for senior leadership. The briefs are influential, but no one has explicitly discussed what the AI model knows, whose perspectives it amplifies, or how confident they should be in its summaries.

### **Practice task / learning activity** 

In cross-functional groups (e.g. strategy, academic, professional services, student voice):

1.  Map your current or planned uses of AI in environmental scanning, trend analysis, or scenario work.

2.  For each use, answer:

    - What assumptions are we making about the model (data sources, language, geography, sector focus)?

    - What types of signals or voices might be missing?

3.  Co-create a one-page “AI Orientation Note” for your foresight set-up that includes:

    - Known strengths and blind spots

    - Appropriate use cases and red lines

    - A short “health warning” to attach to every AI-generated brief.

### **Reflection prompts**

- When leadership read AI-generated briefs, what do they *think* the model is doing? How accurate is that mental model?

- How could misunderstanding model limits distort our sense of risk, urgency, or opportunity?

### **Values in play**

Transparency, humility, stewardship, inclusion.

## Domain 2 – Human–AI Co-Agency

## Designing Roles in Scenario and Simulation Work

### **Scenario** 

A university is running an AI-supported scenario planning workshop about the future of international recruitment. The AI assistant is being used to propose 2035 scenarios, generate stakeholder personas, and summarise table discussions. Participants love the speed but are starting to “vote with their prompts,” letting the model decide which futures feel most plausible.

### **Practice task / learning activity** 

Design a “Co-Agency Charter” for your next foresight or simulation exercise:

1.  Specify what AI is responsible for (e.g. first-draft scenarios, clustering themes, drafting personas, suggesting indicators).

2.  Specify what humans are responsible for (e.g. setting value frames, selecting critical uncertainties, judging plausibility, identifying equity risks).

3.  Create three “collaboration patterns” for different settings:

    - Executive retreat

    - Faculty-level curriculum foresight workshop

    - Operational risk and resilience meeting.  
      For each pattern, define when AI is used, who reviews its outputs, and how disagreements between AI output and human judgement are handled.

### **Reflection prompts**

- In your current foresight practices, where is AI overstepping into decisions that should remain human?

- Conversely, where are humans doing repetitive synthesis that could be safely delegated to AI?

### **Values in play** 

Collaboration, agency, role clarity, accountability.

## Domain 3 – Generative Practice & Innovation

## Experimenting with AI in Environmental Scanning and Trend Analysis

### **Scenario** 

A learning and teaching committee wants to understand emerging global trends in AI-augmented assessment. They set up AI-assisted trend analysis: an automation scrapes policy portals, journals, and sector blogs; GenAI clusters themes and proposes three “innovation fronts” to watch. Committee members are unconvinced, worried the outputs are either too generic or too risky.

### **Practice task / learning activity** 

Run a “Design Studio for AI-Enabled Scanning”:

1.  Using the lesson content, sketch a minimal viable workflow for environmental scanning and trend analysis in your institution (sources, tools, prompts, review points).

2.  Ask GenAI to:

    - Propose 3–4 novel scanning lenses (e.g. “student agency and AI”, “assessment labour models”, “microcredential ecosystems”).

    - Generate contrasting short briefs for each lens (optimistic, pessimistic, and equity-focused variants).

3.  As a group, prototype one concrete micro-innovation (e.g. a fortnightly AI-generated “Trend Pulse” for programme leads) and set clear guardrails (who checks it, how often, how to retire it if harmful).

### **Reflection prompts**

- How can AI-enabled scanning avoid becoming an “innovation theatre” that produces glossy outputs but no change?

- Which experiments feel small and safe enough to try this semester, and which require formal approval?

**Values in play**  
Creative risk-taking, proportionality, inclusion, learning by doing.

## Domain 4 – Ethics, Equity & Impact

## Interrogating Bias in Scenarios and Simulations

### **Scenario** 

An AI-supported scenario planning exercise generates three futures about “AI and student success.” All three, on inspection, centre English-speaking, fee-paying, campus-based students. Distance learners, disabled students, caregivers, Global South partnerships, and community partners are largely absent. The scenarios are elegant but narrow.

### **Practice task / learning activity**

Conduct an “Ethical Futures Audit” of your AI-generated scenarios and simulations:

1.  Select one AI-generated scenario (e.g. from a previous workshop or a fresh output based on Chapter 3).

2.  Identify who appears explicitly, who appears implicitly, and who is absent (students, staff groups, communities, regions, disciplines).

3.  Ask GenAI to generate an alternative version of the same scenario:

    - Centring a minoritised group

    - Framing impacts in terms of justice, accessibility, or decolonial perspectives.

4.  Compare the original and revised scenarios: list three ways strategic conclusions might differ when marginalised perspectives are centred.

### **Reflection prompts**

- What harms could arise if leadership only ever sees futures centred on dominant groups or well-resourced institutions?

- How might you institutionalise the requirement that every AI-generated scenario must have at least one equity-anchored variant?

### **Values in play** 

Equity, justice, accessibility, epistemic plurality.

## Domain 5 – Decision-Making & Governance

## Tracing How AI-Supported Foresight Shapes Power

### **Scenario** 

A governing body receives a polished pack: environmental scans, trend maps, AI-generated stress tests of the institutional plan, and a “recommended pathway” synthesised by an AI assistant from prior strategy documents. Over time, board members start treating the AI-curated pathway as the “neutral” option, even though it embeds previous power dynamics and omissions.

### **Practice task / learning activity** 

Design a governance pattern for AI-supported foresight:

1.  Map a single decision pathway where AI plays a role – for example, “Should we invest heavily in AI-enabled student support systems?”

2.  For each step (scanning, trend analysis, scenario building, stress-testing, operational planning), specify:

    - Where AI is used

    - Who has the right to question or override AI-generated content

    - What must be documented (prompts, model versions, human decisions).

3.  Create a simple “Foresight Decision Log” template capturing:

    - Options considered, futures tested, equity implications, and the final justification.

### **Reflection prompts**

- In your current governance structures, who gains influence from AI-supported foresight, and who risks being marginalised?

- How could transparent logs and participatory review reduce the risk of “AI-washed” decisions?

**Values in play**  
Transparency, accountability, participation, stewardship.

## Domain 6 – Reflection, Learning & Renewal

## Building a Living Foresight Practice

### **Scenario** 

Over three years, an institution runs multiple AI-assisted scanning exercises, foresight workshops, and simulations. Each produces impressive outputs, but they sit in separate folders, owned by different units. There is no shared memory of what was anticipated, what actually happened, or what was learned when plans were stress-tested.

### **Practice task / learning activity** 

Create a “Foresight Learning Log” for your institution or team:

1.  Identify 2–3 past or current foresight activities (e.g. COVID-era scenario planning, AI curriculum mapping, digital transformation stress-testing).

2.  For each, use GenAI to help reconstruct:

    - The scenarios or assumptions used

    - The decisions made

    - What subsequently happened.

3.  With your group, write a short reflective note:

    - What did we overestimate or underestimate?

    - How did AI tools help or hinder?

    - What practices should we formalise for next time (e.g. scheduled scenario updates, equity checks, cross-unit debriefs)?

4.  Capture these as “Design Principles for Future Foresight Work” and store them somewhere findable and shared.

### **Reflection prompts**

- If we looked back in five years, what would we want to have recorded about how we used AI in foresight today?

- How can we ensure that foresight is not a series of disconnected projects but a cumulative, institutional capability?

**Values in play**  
Learning, humility, renewal, continuity.

## Cross-Domain Synthesis Activity

## Designing an AI-Augmented Foresight Cycle for Your Institution

This integrative activity invites participants to connect all six domains into a coherent foresight-to-operations “loop” for their own context.

### **Step 1 – Map your current reality (Awareness & Orientation + Reflection & Renewal)** 

In mixed-role groups, sketch your current foresight cycle on one page:

- How do signals arrive?

- Who interprets trends?

- Where (if at all) are scenarios built or stress-tests run?

- How do insights feed into operational plans?

Annotate this sketch using Domain 1 and Domain 6 lenses: highlight where AI already plays a role, where assumptions are unclear, and where learning is lost between cycles.

**Step 2 – Design your future cycle (Co-Agency + Generative Practice)  **
Now, using the chapter content on environmental scanning, trend analysis, scenario planning, and stress-testing:

1.  Redesign the cycle for a three-year horizon, explicitly deciding:

    - Which steps you want AI to augment (and how)

    - Which steps must remain deeply human, deliberative, and value-intensive.

2.  Ask GenAI to propose 2–3 innovative but realistic enhancements (e.g. an AI-supported Foresight Lab, automated policy-risk digests, or an annual “future of assessment” scenario sprint).

3.  As a group, assess these suggestions for feasibility and ethical integrity.

### **Step 3 – Embed governance and equity (Ethics, Equity & Impact + Decision-Making & Governance) Using Domains 4 and 5:**

1.  Mark on your redesigned cycle where equity checks are performed (e.g. scenario diversification, impact assessments on different learner groups).

2.  Decide where governance artefacts (decision logs, model transparency notes, ethical approvals) must be generated.

3.  Agree on who owns the cycle overall and how diverse perspectives (students, professional services, community/partner organisations) will be included.

### **Step 4 – Commit to one concrete move** 

Each team identifies one actionable step they can implement in the next 6–12 months (e.g. piloting an AI-assisted scanning brief with an explicit equity review, or running a scenario workshop for a single programme area). They document:

- Intended benefits and risks

- Required resources and sponsorship

- How they will evaluate both AI performance and human learning.

This cross-domain task turns the chapter into a live design brief: not just imagining futures, but building the institutional muscle to work with them responsibly.

## Adaptation Tips

## Using This Exercise with Different Audiences

### **For learners/students (e.g. postgraduate education, public policy, or health programmes)**

- Narrow the focus to a single issue (e.g. “future of clinical placements,” “future of research careers,” “future of assessment in my discipline”).

- Simplify tooling: use one AI assistant plus curated documents instead of complex automations.

- Emphasise foundational literacies: interpreting AI-generated scenarios, spotting bias, and articulating their own values in relation to futures work.

- Assess through reflective essays or group presentations on “our preferred future and how to get there,” drawing explicitly on the six domains.

**For educators and institutional teams**

- Treat the six domain activities as modular workshop segments that can be run over several sessions.

- Use real institutional artefacts: current strategic plans, risk registers, committee papers, quality reports.

- Build outputs directly into governance cycles (e.g. feeding scenario insights into programme review, digital strategy, or student experience projects).

- Encourage cross-faculty participation to reflect the ecological, interconnected nature of the futures being discussed.

### **For policy or service professionals (inside or beyond higher education)**

- Reframe examples around service delivery, regulatory risk, workforce planning, or public health rather than only curriculum.

- Focus on Domains 4 and 5 to explore how AI-assisted foresight interacts with accountability, public trust, and regulatory legitimacy.

- Use the cross-domain synthesis activity to co-design an AI-augmented foresight cycle for your department or agency, with explicit public-value and equity tests.

Across all contexts, the exercise should be positioned as iterative: a starting template for developing AI-augmented foresight that can be revisited, refined, and scaled as institutional capability grows.
