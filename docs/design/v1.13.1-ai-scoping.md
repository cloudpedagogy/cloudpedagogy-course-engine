# AI Scoping Contract — v1.13.1

## Status

**Version:** v1.13.1
**Applies to:** Course Engine v1.13+
**Status:** Stable (contractual design decision)

---

## Purpose

This document defines the **AI Scoping contract** used by the CloudPedagogy Course Engine.

AI scoping exists to make the *boundaries, expectations, and governance intent* around AI use **explicit, inspectable, and auditable**, without enforcing compliance or constraining pedagogical design.

This contract intentionally prioritises **human judgement, review, and accountability** over automated enforcement.

---

## What AI Scoping *Is*

AI scoping is:

* A **declarative governance artefact** authored in `course.yml`
* **Non-normative** (it does not judge correctness or quality)
* **Non-enforced** (it never blocks builds or validation by itself)
* **Hashed and recorded** in `manifest.json` for auditability
* **Stable across time**, enabling reviewers to verify what was declared at build time

AI scoping answers the question:

> *“What are the stated boundaries and expectations for AI use in this course?”*

---

## What AI Scoping Is *Not*

AI scoping is **not**:

* A compliance mechanism
* A policy enforcement system
* A behavioural monitoring tool
* A scoring or maturity model
* A substitute for institutional policy
* A guarantee of ethical or appropriate AI use

The Course Engine **does not interpret, validate, or police** AI scoping content.

---

## Relationship to Design Intent

AI scoping is **structurally separate** from `design_intent`.

* `design_intent` explains *why* the course is designed as it is
* `ai_scoping` explains *how AI use is bounded and framed*

Both may coexist, but neither depends on the other.

This separation prevents:

* Overloading design intent with policy detail
* Treating reflective intent as enforceable rules

---

## Relationship to Signals

AI scoping interacts with the **absence signalling system** in a limited, deliberate way:

* If AI positioning exists **without** AI scoping, the system may emit:

  * `SIG-AI-001` (informational)
* If AI scoping exists, **no AI scoping–related signal is emitted**

Signals:

* Are advisory only
* Never fail validation by default
* Exist to prompt human review, not machine action

---

## Manifest Recording

When present, AI scoping is recorded in `manifest.json` as:

* `present: true`
* `hash_sha256: <stable hash>`

Optionally:

* A short human-readable summary

The **hash is the contract**:

> If the hash matches, the declared scoping is the same as at build time.

No semantic interpretation is performed during build, validation, render, or refresh.

---

## Why Hashing (Not Interpretation)

Hashing provides:

* Deterministic auditability
* Reviewer trust without automation bias
* Protection against silent changes
* Compatibility with institutional review workflows

Interpretation would:

* Create false precision
* Invite enforcement creep
* Shift responsibility away from humans

This contract explicitly rejects that path.

---

## Design Principles

This contract is governed by the following principles:

1. **Capability over compliance**
2. **Explicit intent over inferred behaviour**
3. **Human judgement over algorithmic authority**
4. **Auditability without enforcement**
5. **Restraint as a design feature**

---

## Future Evolution

Any future changes to AI scoping MUST:

* Preserve non-enforcement by default
* Maintain backward compatibility
* Be documented as a new contract version
* Avoid retroactive interpretation of historical manifests

Breaking these principles constitutes a **major version change**.

---

## Summary

AI scoping in the Course Engine is:

> A stable, declarative boundary-setting mechanism designed to support trust, review, and accountability — not control.

This contract exists to keep that boundary clear.
